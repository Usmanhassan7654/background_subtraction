{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Background Remove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WMQHvj9riZ3",
        "outputId": "9f775824-905d-4593-b367-5d3a3d9b5c43"
      },
      "source": [
        "!git clone https://github.com/shreyas-bk/U-2-Net.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'U-2-Net'...\n",
            "remote: Enumerating objects: 520, done.\u001b[K\n",
            "remote: Total 520 (delta 0), reused 0 (delta 0), pack-reused 520\u001b[K\n",
            "Receiving objects: 100% (520/520), 12.39 MiB | 25.27 MiB/s, done.\n",
            "Resolving deltas: 100% (234/234), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6c0jL4drd7m"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def saliency_detection2(inputImgPath):\n",
        "   \n",
        "\n",
        "    # Load the input image.\n",
        "    inputImage = cv2.imread(inputImgPath) \n",
        "\n",
        "    # Path of the input images directory of the model.\n",
        "    INPUTIMGDIR = 'U-2-Net/images/'\n",
        "\n",
        "    # Check if the input images directory does not already exist.\n",
        "    if not os.path.exists(INPUTIMGDIR):\n",
        "\n",
        "        # Make the input directory.   \n",
        "        os.mkdir(INPUTIMGDIR)\n",
        "\n",
        "    # Extract the name of the input image.\n",
        "    inputImgName = inputImgPath.split('/')[-1].split('.')[0]\n",
        "\n",
        "    # Write the input image to the directory where input images for the model are stored.\n",
        "    cv2.imwrite(INPUTIMGDIR + inputImgName + '.jpg', inputImage)\n",
        "\n",
        "    # The path of the output images directory of the model.\n",
        "    OUTPUTIMGDIR = 'U-2-Net/results/'\n",
        "\n",
        "    # Check if the output images directory does not already exist.\n",
        "    if not os.path.exists(OUTPUTIMGDIR):\n",
        "\n",
        "        # Make the ouput directory.   \n",
        "        os.mkdir(OUTPUTIMGDIR)\n",
        "\n",
        "    # Change the current directory to the U-2-Net directory.\n",
        "    os.chdir('U-2-Net/')\n",
        "\n",
        "    # Perform salient object detection on the image stored in the input directory of the model\n",
        "    # and store the output image into the output directory.\n",
        "    !python -W ignore u2net_test.py\n",
        "\n",
        "    # Go back.\n",
        "    os.chdir('../')\n",
        "\n",
        "    # Remove the image from the input directory.\n",
        "    os.remove(INPUTIMGDIR + inputImgName + '.jpg')\n",
        "\n",
        "    # Load the output image.\n",
        "    # The model outputs it with the same name but in .png format.\n",
        "    outputImg = cv2.imread(OUTPUTIMGDIR + inputImgName + '.png')\n",
        "\n",
        "    # Return the output image.\n",
        "    return outputImg\n",
        "\n",
        "def remove_background2(srcImg, outputImg, THRESHOLD = 0.3):\n",
        "   \n",
        "\n",
        "    # Create a copy of a output image channel and normalize it by dividing it by 255 which makes pixel values range 0-1.\n",
        "    mask =  outputImg.copy()[:,:,0] / 255\n",
        "\n",
        "    # Update all the values below or equal to the threshold to zero.\n",
        "    mask[mask <= THRESHOLD] = 0\n",
        "\n",
        "    # Update all the values greater than the threshold to one.\n",
        "    mask[mask > THRESHOLD] = 1\n",
        "\n",
        "    # Create a copy of the source image.\n",
        "    obj = srcImg.copy()\n",
        "\n",
        "    # Update all the values of the source image to zero at indexes where the mask values are zero i.e. background.\n",
        "    obj[mask == 0] = 0\n",
        "\n",
        "    # Return the extracted object from the source image and the mask image.\n",
        "    return obj, mask\n",
        "\n",
        "def merge2(obj, bgImg, mask):\n",
        "   \n",
        "\n",
        "    # Resize the background according to the source (foreground) image shape.\n",
        "    #print(bgImg.shape)\n",
        "    bgImg = cv2.resize(bgImg, (obj.shape[1], obj.shape[0]))\n",
        "    #print(bgImg.shape)\n",
        "    \n",
        "    # Update all the values of the background image to zero at indexes where the mask values are one. \n",
        "    # This is where the foreground (object) will be inserted.\n",
        "    bgImg [mask == 1] = 0\n",
        "    \n",
        "    # Merge the foreground (object) and the background.\n",
        "    mergedImage = bgImg + obj\n",
        "    \n",
        "    # Return the merged image.\n",
        "    return mergedImage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sNhVYD-SKgA"
      },
      "source": [
        "x = os.listdir(\"/content/images\")\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk0AXu9JOYho",
        "outputId": "8db575ad-36ea-40c8-981b-e1b6793ecf3b"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "\n",
        "# count2 = 0\n",
        "count = 11\n",
        "# for j in range(2,9):\n",
        "\n",
        "x = os.listdir(\"/content/images\")\n",
        "#count2 = count2 + 1\n",
        "  \n",
        "for i in x:\n",
        "\n",
        "  #print(i)\n",
        "  outimg = saliency_detection2(\"/content/images/\"+str(i))\n",
        "  #outimg = cv2.flip(outimg2, 0)\n",
        "\n",
        "  img2 = cv2.imread(\"/content/images/\"+str(i))\n",
        "  height,width = img2.shape[0], img2.shape[1]\n",
        "  #img2 = cv2.flip(img22, 0)\n",
        "\n",
        "  #bgImg = cv2.imread(\"/content/top\"+str(j)+\".jpg\")\n",
        "  bgImg = np.zeros((height,width,3), np.uint8)\n",
        "  bgImg[:,:] = (199,195,195)\n",
        "\n",
        "\n",
        "  obj, mask = remove_background2(img2, outimg, THRESHOLD = 0.3)\n",
        "\n",
        "  final_img = merge2(obj, bgImg, mask)\n",
        "\n",
        "  #full_final_img = cv2.resize(final_img, (width, height))\n",
        "\n",
        "  cv2.imwrite(\"/content/out_img/new_o_gen\"+str(count)+\".jpg\", final_img)\n",
        "  count = count + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/U-2-Net/images/frame2603.jpg']\n",
            "inferencing: frame2603.jpg\n",
            "['/content/U-2-Net/images/frame264.jpg']\n",
            "inferencing: frame264.jpg\n",
            "['/content/U-2-Net/images/frame2796.jpg']\n",
            "inferencing: frame2796.jpg\n",
            "['/content/U-2-Net/images/frame2232.jpg']\n",
            "inferencing: frame2232.jpg\n",
            "['/content/U-2-Net/images/frame2724.jpg']\n",
            "inferencing: frame2724.jpg\n",
            "['/content/U-2-Net/images/frame660.jpg']\n",
            "inferencing: frame660.jpg\n",
            "['/content/U-2-Net/images/frame2256.jpg']\n",
            "inferencing: frame2256.jpg\n",
            "['/content/U-2-Net/images/frame862.jpg']\n",
            "inferencing: frame862.jpg\n",
            "['/content/U-2-Net/images/frame1673.jpg']\n",
            "inferencing: frame1673.jpg\n",
            "['/content/U-2-Net/images/frame287.jpg']\n",
            "inferencing: frame287.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MoS0kkprd8E"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "def bordermaker(im):\n",
        "  bordersize = 200\n",
        "  border = cv2.copyMakeBorder(\n",
        "      im,\n",
        "      top=bordersize,\n",
        "      bottom=bordersize,\n",
        "      left=bordersize,\n",
        "      right=bordersize,\n",
        "      borderType=cv2.BORDER_CONSTANT,\n",
        "      value=[0, 0, 0]\n",
        "  )\n",
        "  return border\n",
        "\n",
        "count2 = 0\n",
        "count = 176\n",
        "for j in range(2,9):\n",
        "\n",
        "  x = os.listdir(\"/content/img3\")\n",
        "  count2 = count2 + 1\n",
        "  \n",
        "  for i in x:\n",
        "\n",
        "\n",
        "    outimg = saliency_detection2(\"/content/img3/\"+str(i))\n",
        "    bordered_out = bordermaker(outimg)\n",
        "    #outimg = cv2.flip(outimg2, 0)\n",
        "\n",
        "    img2 = cv2.imread(\"/content/img3/\"+str(i))\n",
        "    height,width = img2.shape[0], img2.shape[1]\n",
        "    bordered = bordermaker(img2)\n",
        "    #img2 = cv2.flip(img22, 0)\n",
        "\n",
        "    bgImg = cv2.imread(\"/content/top\"+str(j)+\".jpg\")\n",
        "\n",
        "    obj2, mask2 = remove_background2(bordered, bordered_out, THRESHOLD = 0.3)\n",
        "\n",
        "\n",
        "    angle = 270\n",
        "    rows, cols, channels = obj2.shape\n",
        "    rows1, cols1= mask2.shape\n",
        "\n",
        "    \n",
        "    # Rotate image from center of image with an angle of 45 degrees at the same scale.\n",
        "    rotation_matrix = cv2.getRotationMatrix2D((cols/2,rows/2), angle, 1)\n",
        "\n",
        "    rotation_matrix1 = cv2.getRotationMatrix2D((cols1/2,rows1/2), angle, 1)\n",
        "    \n",
        "    # Apply the transformation\n",
        "    obj = cv2.warpAffine(obj2, rotation_matrix, (cols,rows))\n",
        "    mask = cv2.warpAffine(mask2, rotation_matrix1, (cols1,rows1))\n",
        "\n",
        "\n",
        "\n",
        "    final_img = merge2(obj, bgImg, mask)\n",
        "\n",
        "    full_final_img = cv2.resize(final_img, (width, height))\n",
        "\n",
        "    cv2.imwrite(\"/content/new/gen\"+str(count)+\".jpg\", full_final_img)\n",
        "    count = count + 1\n",
        "\n",
        "# cv2_imshow(img2)\n",
        "# cv2_imshow(mask)\n",
        "# cv2_imshow(outimg)\n",
        "# cv2_imshow(obj)\n",
        "#cv2_imshow(final_img)\n",
        "# cv2.waitKey(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT3E99TNt6b6"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "im = cv2.imread('/content/Images/frame2609.jpg')\n",
        "row, col = im.shape[:2]\n",
        "bottom = im[row-2:row, 0:col]\n",
        "mean = cv2.mean(bottom)[0]\n",
        "\n",
        "bordersize = 10\n",
        "border = cv2.copyMakeBorder(\n",
        "    im,\n",
        "    top=bordersize,\n",
        "    bottom=bordersize,\n",
        "    left=bordersize,\n",
        "    right=bordersize,\n",
        "    borderType=cv2.BORDER_CONSTANT,\n",
        "    value=[0, 0, 0]\n",
        ")\n",
        "\n",
        "cv2_imshow(im)\n",
        "cv2_imshow(bottom)\n",
        "cv2_imshow(border)\n",
        "print(im.shape)\n",
        "print(border.shape)\n",
        "#print(mean)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "NmkMyckGjqFH",
        "outputId": "357bbe49-c5a3-44c0-decd-c1a8dea89dc0"
      },
      "source": [
        "import cv2  # Not actually necessary if you just want to create an image.\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "blank_image = np.zeros((400,400,3), np.uint8)\n",
        "blank_image[:,:] = (199,195,195)      # (B, G, R)\n",
        "#blank_image[:,400//2:400] = (0,255,0)\n",
        "\n",
        "cv2_imshow(blank_image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGQCAIAAAAP3aGbAAAFNElEQVR4nO3UMQ0AIADAMMC/Kw5sYYGPLGkV7Nrc+wyAgvU7AOCVYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkGBaQYVhAhmEBGYYFZBgWkGFYQIZhARmGBWQYFpBhWECGYQEZhgVkXKmIBW0qXgMlAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=400x400 at 0x7FD9A254CE10>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHZli6T88IHL"
      },
      "source": [
        "# For Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E26YiZ0I8MJ1"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def saliency_detection(inputImgPath):\n",
        "   \n",
        "\n",
        "    # Load the input image.\n",
        "    #inputImage = cv2.imread(inputImgPath) \n",
        "\n",
        "    # Path of the input images directory of the model.\n",
        "    INPUTIMGDIR = 'U-2-Net/images/'\n",
        "\n",
        "    # Check if the input images directory does not already exist.\n",
        "    if not os.path.exists(INPUTIMGDIR):\n",
        "\n",
        "        # Make the input directory.   \n",
        "        os.mkdir(INPUTIMGDIR)\n",
        "\n",
        "    # Extract the name of the input image.\n",
        "    inputImgName = \"img\"\n",
        "\n",
        "    # Write the input image to the directory where input images for the model are stored.\n",
        "    cv2.imwrite(INPUTIMGDIR + inputImgName + '.jpg', inputImgPath)\n",
        "\n",
        "    # The path of the output images directory of the model.\n",
        "    OUTPUTIMGDIR = 'U-2-Net/results/'\n",
        "\n",
        "    # Check if the output images directory does not already exist.\n",
        "    if not os.path.exists(OUTPUTIMGDIR):\n",
        "\n",
        "        # Make the ouput directory.   \n",
        "        os.mkdir(OUTPUTIMGDIR)\n",
        "\n",
        "    # Change the current directory to the U-2-Net directory.\n",
        "    os.chdir('U-2-Net/')\n",
        "\n",
        "    # Perform salient object detection on the image stored in the input directory of the model\n",
        "    # and store the output image into the output directory.\n",
        "    !python -W ignore u2net_test.py\n",
        "\n",
        "    # Go back.\n",
        "    os.chdir('../')\n",
        "\n",
        "    # Remove the image from the input directory.\n",
        "    os.remove(INPUTIMGDIR + inputImgName + '.jpg')\n",
        "\n",
        "    # Load the output image.\n",
        "    # The model outputs it with the same name but in .png format.\n",
        "    outputImg = cv2.imread(OUTPUTIMGDIR + inputImgName + '.png')\n",
        "\n",
        "    # Return the output image.\n",
        "    return outputImg\n",
        "\n",
        "def remove_background(srcImg, outputImg, THRESHOLD = 0.3):\n",
        "   \n",
        "\n",
        "    # Create a copy of a output image channel and normalize it by dividing it by 255 which makes pixel values range 0-1.\n",
        "    mask =  outputImg.copy()[:,:,0] / 255\n",
        "\n",
        "    # Update all the values below or equal to the threshold to zero.\n",
        "    mask[mask <= THRESHOLD] = 0\n",
        "\n",
        "    # Update all the values greater than the threshold to one.\n",
        "    mask[mask > THRESHOLD] = 1\n",
        "\n",
        "    # Create a copy of the source image.\n",
        "    obj = srcImg.copy()\n",
        "\n",
        "    # Update all the values of the source image to zero at indexes where the mask values are zero i.e. background.\n",
        "    obj[mask == 0] = 0\n",
        "\n",
        "    # Return the extracted object from the source image and the mask image.\n",
        "    return obj, mask\n",
        "\n",
        "def merge(obj, bgImg, mask):\n",
        "   \n",
        "\n",
        "    # Resize the background according to the source (foreground) image shape.\n",
        "    bgImg = cv2.resize(bgImg, (obj.shape[1], obj.shape[0]))\n",
        "    \n",
        "    # Update all the values of the background image to zero at indexes where the mask values are one. \n",
        "    # This is where the foreground (object) will be inserted.\n",
        "    bgImg [mask == 1] = 0\n",
        "    \n",
        "    # Merge the foreground (object) and the background.\n",
        "    mergedImage = bgImg + obj\n",
        "    \n",
        "    # Return the merged image.\n",
        "    return mergedImage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLJD1r4761VJ",
        "outputId": "2322b254-bea6-4084-9d1f-9096aa99a5c4"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/cat.mp4\")\n",
        "frame_width = int(cap.get(3))\n",
        "\n",
        "frame_height = int(cap.get(4))\n",
        "out1 = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'),20, (frame_width,frame_height))\n",
        "while True:\n",
        "  try:\n",
        "    _, img = cap.read()\n",
        "    outimg = saliency_detection(img)\n",
        "\n",
        "    #img2 = cv2.imread(\"/content/images/\"+str(i))\n",
        "\n",
        "    bgImg = cv2.imread(\"/content/g.jpg\")\n",
        "\n",
        "    obj, mask = remove_background(img, outimg, THRESHOLD = 0.7)\n",
        "\n",
        "    final_img = merge(obj, bgImg, mask)\n",
        "    out1.write(final_img)\n",
        "  except:\n",
        "    print(\"Video End.....\")\n",
        "    break\n",
        "    cap.release()\n",
        "    out1.release()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "['/content/U-2-Net/images/img.jpg']\n",
            "inferencing: img.jpg\n",
            "Video End.....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-xnsiiWr8vI",
        "outputId": "d021cf65-6339-413e-9872-fbf2cb051cef"
      },
      "source": [
        "cv2.imwrite(\"final_img4.jpg\", final_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyFvFg11-tH5",
        "outputId": "bdbc45d7-86a9-49d8-c9a8-35c2a0ba1534"
      },
      "source": [
        "!zip -r /content/out_imgs.zip /content/out_img"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/out_img/ (stored 0%)\n",
            "  adding: content/out_img/new_o_gen2.jpg (deflated 21%)\n",
            "  adding: content/out_img/gen16.jpg (deflated 22%)\n",
            "  adding: content/out_img/new_o_gen19.jpg (deflated 29%)\n",
            "  adding: content/out_img/new_o_gen12.jpg (deflated 20%)\n",
            "  adding: content/out_img/new_o_gen20.jpg (deflated 20%)\n",
            "  adding: content/out_img/new_o_gen1.jpg (deflated 55%)\n",
            "  adding: content/out_img/gen1.jpg (deflated 53%)\n",
            "  adding: content/out_img/gen6.jpg (deflated 20%)\n",
            "  adding: content/out_img/gen3.jpg (deflated 24%)\n",
            "  adding: content/out_img/new_o_gen15.jpg (deflated 28%)\n",
            "  adding: content/out_img/gen14.jpg (deflated 13%)\n",
            "  adding: content/out_img/new_o_gen7.jpg (deflated 25%)\n",
            "  adding: content/out_img/new_o_gen5.jpg (deflated 29%)\n",
            "  adding: content/out_img/gen18.jpg (deflated 20%)\n",
            "  adding: content/out_img/new_o_gen18.jpg (deflated 27%)\n",
            "  adding: content/out_img/new_o_gen9.jpg (deflated 29%)\n",
            "  adding: content/out_img/gen13.jpg (deflated 55%)\n",
            "  adding: content/out_img/new_o_gen4.jpg (deflated 25%)\n",
            "  adding: content/out_img/gen9.jpg (deflated 25%)\n",
            "  adding: content/out_img/new_o_gen3.jpg (deflated 13%)\n",
            "  adding: content/out_img/new_o_gen11.jpg (deflated 53%)\n",
            "  adding: content/out_img/gen7.jpg (deflated 55%)\n",
            "  adding: content/out_img/gen15.jpg (deflated 25%)\n",
            "  adding: content/out_img/gen5.jpg (deflated 29%)\n",
            "  adding: content/out_img/gen10.jpg (deflated 22%)\n",
            "  adding: content/out_img/gen17.jpg (deflated 29%)\n",
            "  adding: content/out_img/new_o_gen8.jpg (deflated 28%)\n",
            "  adding: content/out_img/gen11.jpg (deflated 29%)\n",
            "  adding: content/out_img/new_o_gen6.jpg (deflated 22%)\n",
            "  adding: content/out_img/gen2.jpg (deflated 13%)\n",
            "  adding: content/out_img/gen8.jpg (deflated 13%)\n",
            "  adding: content/out_img/new_o_gen16.jpg (deflated 21%)\n",
            "  adding: content/out_img/gen12.jpg (deflated 20%)\n",
            "  adding: content/out_img/new_o_gen17.jpg (deflated 24%)\n",
            "  adding: content/out_img/new_o_gen10.jpg (deflated 20%)\n",
            "  adding: content/out_img/new_o_gen13.jpg (deflated 13%)\n",
            "  adding: content/out_img/new_o_gen14.jpg (deflated 24%)\n",
            "  adding: content/out_img/gen4.jpg (deflated 21%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAkLkseu-s_W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}